{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd \n",
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from skimage import io \n",
    "import pickle\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds_to_df(preds_path):\n",
    "\n",
    "    coco_train = COCO('../coco/annotations/instances_train2014.json')\n",
    "    coco_val = COCO('../coco/annotations/instances_val2014.json')\n",
    "\n",
    "    with open(preds_path) as fp:\n",
    "        model_preds = json.load(fp)\n",
    "\n",
    "    preproc = []\n",
    "\n",
    "    for i in model_preds:\n",
    "        img_id = str(i['img_id'])\n",
    "        if 'val' in img_id:\n",
    "            loaded_img = coco_val.loadImgs([int(img_id[-6:])])\n",
    "        else:\n",
    "            loaded_img = coco_train.loadImgs([int(img_id[-6:])])\n",
    "        img_url = loaded_img[0]['coco_url']\n",
    "\n",
    "        label = i['label']\n",
    "        label_list = list(label.keys())\n",
    "        i['label'] = ', '.join(label_list)\n",
    "        i['img_url'] = img_url\n",
    "        preproc.append(i)\n",
    "\n",
    "    df = pd.json_normalize(preproc)\n",
    "\n",
    "    return df\n",
    "\n",
    "def validation_per_question(df):\n",
    "    validation_questions = {}\n",
    "    unique_questions = df['question_type'].unique()\n",
    "    grouped = df.groupby(df.question_type)\n",
    "    for ques in unique_questions:\n",
    "        df1 = grouped.get_group(ques)\n",
    "        val_score = df1['score'].sum() / len(df1)\n",
    "        validation_questions[ques] = val_score\n",
    "    return validation_questions\n",
    "    \n",
    "def validation_per_answer(df):\n",
    "    validation_answers = {}\n",
    "    unique_answers= df['answer_type'].unique()\n",
    "    grouped = df.groupby(df.answer_type)\n",
    "    for ans in unique_answers:\n",
    "        df1 = grouped.get_group(ans)\n",
    "        val_score = df1['score'].sum() / len(df1)\n",
    "        validation_answers[ans] = val_score\n",
    "    return validation_answers\n",
    "\n",
    "def plot_preds_question_type(df):\n",
    "    unique_questions = df['question_type'].unique()\n",
    "\n",
    "    grouped = df.groupby(df.question_type)\n",
    "    for ques in unique_questions:\n",
    "        print(\"QUESTION: \", ques)\n",
    "        df_ques = grouped.get_group(ques)\n",
    "        for j in range(3):\n",
    "            example = df_ques.iloc[[j]]\n",
    "            ans = example['answer']\n",
    "            question = example['question']\n",
    "            label = example['label']\n",
    "            img_url = example['img_url']\n",
    "            a = io.imread(img_url)\n",
    "            plt.figure()\n",
    "            plt.imshow(a)\n",
    "            plt.title(\"Labels: \"+ label + \"\\n Preds: \" + ans + \"\\n Question: \" + question)\n",
    "\n",
    "def compare_dfs_stats(df1, df2):\n",
    "    # take the intersection of two dfs and print question types, answer types, and target stats\n",
    "    df1_question_ids = set(df1['question_id'].tolist())\n",
    "    df2_question_ids = set(df2['question_id'].tolist())\n",
    "\n",
    "    ids_intersection = df1_question_ids.intersection(df2_question_ids)\n",
    "\n",
    "    df_intersection = df1[df1['question_id'].isin(ids_intersection)]\n",
    "\n",
    "\n",
    "    df_intersection_questions = df_intersection['question_type'].unique()\n",
    "    df_intersection_questions_count = df_intersection['question_type'].value_counts()\n",
    "    df_intersection_questions_count.plot(kind='pie')\n",
    "\n",
    "    # segment df_intersection by question type and plot preds \n",
    "    plot_preds_question_type(df_intersection, df_intersection_questions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df_intersection_answers = df_intersection['answer_type'].unique()\n",
    "    df_intersection_answers_count = df_intersection['answer_type'].value_counts()\n",
    "    df_intersection_answers_count.plot(kind='pie')\n",
    "\n",
    "    all_targets = []\n",
    "    df_intersection_targets = df_intersection['label'].tolist()\n",
    "    for i in df_intersection_targets:\n",
    "        target_list = [x.strip() for x in i.split(',')]\n",
    "        all_targets.extend(target_list)\n",
    "\n",
    "    #convert list to string and generate\n",
    "    unique_string=(\" \").join(all_targets)\n",
    "    wordcloud = WordCloud(width = 1000, height = 500).generate(unique_string)\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def df_stats(df):\n",
    "    \n",
    "    df_questions = df['question_type'].unique()\n",
    "    df_question_counts = df['question_type'].value_counts()\n",
    "    df_question_counts.plot(kind='pie')\n",
    "\n",
    "\n",
    "    df_answers = df['answer_type'].unique()\n",
    "    df_answers_count = df['answer_type'].value_counts()\n",
    "    df_answers_count.plot(kind='pie')\n",
    "\n",
    "\n",
    "    df_targets = df['label'].tolist()\n",
    "    all_targets = []\n",
    "    for i in df_targets:\n",
    "        target_list = [x.strip() for x in i.split(',')]\n",
    "        all_targets.extend(target_list)\n",
    "\n",
    "    #convert list to string and generate\n",
    "    unique_string=(\" \").join(all_targets)\n",
    "    wordcloud = WordCloud(width = 1000, height = 500).generate(unique_string)\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plot_preds_question_type(df)\n",
    "\n",
    "def calc_question_types(df):\n",
    "    questions = df['Question'].tolist()\n",
    "    questions = [i[0].lower() for i in questions]\n",
    "    df['Question'] = questions\n",
    "\n",
    "    with open(\"../../../data/vqa/mscoco_question_types.txt\") as f:\n",
    "        question_types_list = f.read().splitlines() \n",
    "    question_types_list = list(set(question_types_list))\n",
    "    question_types_list = sorted(question_types_list, key=len) \n",
    "    question_types_list.reverse()\n",
    "\n",
    "    df_question_types = []\n",
    "\n",
    "    for idx, question in enumerate(questions):\n",
    "        counter = 0\n",
    "        matches = []\n",
    "        for question_type in question_types_list:  \n",
    "            if question.startswith(question_type):\n",
    "                matches.append(question_type)\n",
    "        if len(matches) != 0:\n",
    "            quest_type_max = max(matches, key=len)\n",
    "            df_question_types.append(quest_type_max)\n",
    "            counter+=1\n",
    "        if counter == 0:\n",
    "            df_question_types.append('none of the above')\n",
    "\n",
    "    assert len(df_question_types) == len(questions)\n",
    "\n",
    "    df['question_type'] = df_question_types\n",
    "    return df\n",
    "\n",
    "def variability_histogram(base_path, sampling_ids=None):\n",
    "    df = pd.read_pickle(base_path+\"datamap_metrics.pkl\")\n",
    "    df = calc_question_types(df)\n",
    "    if sampling_ids != None:\n",
    "        with open(sampling_ids, 'rb') as f:\n",
    "            sampled_ids = pickle.load(f)\n",
    "        df = df.loc[df['question_id'].isin(sampled_ids)]\n",
    "    unique_questions = df['question_type'].unique()\n",
    "    grouped = df.groupby(df.question_type)\n",
    "    for ques in unique_questions:\n",
    "        df1 = grouped.get_group(ques)\n",
    "        plt.figure()\n",
    "        sns.histplot(df1['variability'].tolist(), kde=True).set(title=ques)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def confidence_histogram(base_path, sampling_ids=None):\n",
    "    df = pd.read_pickle(base_path+\"datamap_metrics.pkl\")\n",
    "    df = calc_question_types(df)\n",
    "    if sampling_ids != None:\n",
    "        with open(sampling_ids, 'rb') as f:\n",
    "            sampled_ids = pickle.load(f)\n",
    "        df = df.loc[df['question_id'].isin(sampled_ids)]\n",
    "    unique_questions = df['question_type'].unique()\n",
    "    grouped = df.groupby(df.question_type)\n",
    "    for ques in unique_questions:\n",
    "        df1 = grouped.get_group(ques)\n",
    "        plt.figure()\n",
    "        sns.histplot(df1['confidence'].tolist(), kde=True).set(title=ques)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def compare_dfs(full_df, sampled_df):\n",
    "    # segment all the preds that full model got wrong -- 0.0\n",
    "    # segment all the preds sampled model got right -- > 0.0 \n",
    "    # case 1 - sampled model gets it wrong, full model gets it right\n",
    "    # case 2 - sampled model gets it right, full model gets it wrong\n",
    "\n",
    "    full_df_wrong_preds = full_df[full_df['score'] == 0.0]\n",
    "    sampled_df_wrong_preds = sampled_df[sampled_df['score'] == 0.0]\n",
    "\n",
    "    full_df_right_preds = full_df[full_df['score'] > 0.0]\n",
    "    sampled_df_right_preds = sampled_df[sampled_df['score'] > 0.0]\n",
    "\n",
    "    # case 1:\n",
    "    compare_dfs_stats(full_df_wrong_preds, sampled_df_right_preds)\n",
    "    # case 2: \n",
    "    compare_dfs_stats(full_df_right_preds, sampled_df_wrong_preds)\n",
    "\n",
    "    # independent of overlap, look at what each model is getting wrong -- question types, target types, and for each quest type and target type, plot a few\n",
    "    df_stats(full_df_wrong_preds)\n",
    "    df_stats(sampled_df_wrong_preds)\n",
    "    df_stats(full_df)\n",
    "    df_stats(sampled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=9.45s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=5.25s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "normal_near_mode_var_path = '/home/jaspreet/vl-pretraining/snap/vqa/lxr111_multilabel_normal_near_mode_var0.1_0.4_results/minival_predict.json'\n",
    "#global_random_path = ''\n",
    "beta_pvals_var_path = '/home/jaspreet/vl-pretraining/snap/vqa/lxr111_multilabel_beta_pvals_var_21_results/minival_predict.json'\n",
    "full_model_path = '/home/jaspreet/vl-pretraining/snap/vqa/lxr111_multilabel_full_run_results/minival_predict.json'\n",
    "base_path = '../../../snap/vqa/lxr111_multilabel_full_run_3/'\n",
    "\n",
    "df_normal_near_mode_var = preds_to_df(normal_near_mode_var_path)\n",
    "df_beta_pvals_var = preds_to_df(beta_pvals_var_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_type</th>\n",
       "      <th>img_id</th>\n",
       "      <th>label</th>\n",
       "      <th>question</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_type</th>\n",
       "      <th>score</th>\n",
       "      <th>img_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pink</td>\n",
       "      <td>other</td>\n",
       "      <td>COCO_val2014_000000393267</td>\n",
       "      <td>black, blonde</td>\n",
       "      <td>What color is the woman's shirt on the left?</td>\n",
       "      <td>393267000</td>\n",
       "      <td>what color is the</td>\n",
       "      <td>0.0</td>\n",
       "      <td>http://images.cocodataset.org/val2014/COCO_val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wine</td>\n",
       "      <td>other</td>\n",
       "      <td>COCO_val2014_000000393267</td>\n",
       "      <td>wine</td>\n",
       "      <td>What type of beverage is being displayed?</td>\n",
       "      <td>393267001</td>\n",
       "      <td>what type of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://images.cocodataset.org/val2014/COCO_val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>costume</td>\n",
       "      <td>other</td>\n",
       "      <td>COCO_val2014_000000393267</td>\n",
       "      <td>fashion, style, they aren't</td>\n",
       "      <td>Why are some people wearing hats?</td>\n",
       "      <td>393267002</td>\n",
       "      <td>why</td>\n",
       "      <td>0.0</td>\n",
       "      <td>http://images.cocodataset.org/val2014/COCO_val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meeting</td>\n",
       "      <td>other</td>\n",
       "      <td>COCO_val2014_000000393267</td>\n",
       "      <td>wedding, wine, wine tasting</td>\n",
       "      <td>What kind of event are the people involved in?</td>\n",
       "      <td>393267003</td>\n",
       "      <td>what kind of</td>\n",
       "      <td>0.0</td>\n",
       "      <td>http://images.cocodataset.org/val2014/COCO_val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brick</td>\n",
       "      <td>other</td>\n",
       "      <td>COCO_val2014_000000262228</td>\n",
       "      <td>brick, bricks</td>\n",
       "      <td>What is the ground made of?</td>\n",
       "      <td>262228000</td>\n",
       "      <td>what is the</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://images.cocodataset.org/val2014/COCO_val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25989</th>\n",
       "      <td>10</td>\n",
       "      <td>number</td>\n",
       "      <td>COCO_val2014_000000131063</td>\n",
       "      <td>100, 20, 40, 50, lot, many</td>\n",
       "      <td>How many tiles are there?</td>\n",
       "      <td>131063001</td>\n",
       "      <td>how many</td>\n",
       "      <td>0.0</td>\n",
       "      <td>http://images.cocodataset.org/val2014/COCO_val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25990</th>\n",
       "      <td>no</td>\n",
       "      <td>yes/no</td>\n",
       "      <td>COCO_val2014_000000131063</td>\n",
       "      <td>yes</td>\n",
       "      <td>Was this photo taken at someone's house?</td>\n",
       "      <td>131063002</td>\n",
       "      <td>was</td>\n",
       "      <td>0.0</td>\n",
       "      <td>http://images.cocodataset.org/val2014/COCO_val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25991</th>\n",
       "      <td>person</td>\n",
       "      <td>other</td>\n",
       "      <td>COCO_val2014_000000131063</td>\n",
       "      <td>family, people, woman, women</td>\n",
       "      <td>Who uses this bathroom?</td>\n",
       "      <td>131063003</td>\n",
       "      <td>none of the above</td>\n",
       "      <td>0.0</td>\n",
       "      <td>http://images.cocodataset.org/val2014/COCO_val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25992</th>\n",
       "      <td>marble</td>\n",
       "      <td>other</td>\n",
       "      <td>COCO_val2014_000000131063</td>\n",
       "      <td>bathroom, don't know, not sure</td>\n",
       "      <td>What is the name of this his and her bathroom?</td>\n",
       "      <td>131063004</td>\n",
       "      <td>what is the name</td>\n",
       "      <td>0.0</td>\n",
       "      <td>http://images.cocodataset.org/val2014/COCO_val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25993</th>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>COCO_val2014_000000131063</td>\n",
       "      <td>cluttered</td>\n",
       "      <td>Is this bathroom clean or clutter?</td>\n",
       "      <td>131063005</td>\n",
       "      <td>is this</td>\n",
       "      <td>0.0</td>\n",
       "      <td>http://images.cocodataset.org/val2014/COCO_val...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25994 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        answer answer_type                     img_id  \\\n",
       "0         pink       other  COCO_val2014_000000393267   \n",
       "1         wine       other  COCO_val2014_000000393267   \n",
       "2      costume       other  COCO_val2014_000000393267   \n",
       "3      meeting       other  COCO_val2014_000000393267   \n",
       "4        brick       other  COCO_val2014_000000262228   \n",
       "...        ...         ...                        ...   \n",
       "25989       10      number  COCO_val2014_000000131063   \n",
       "25990       no      yes/no  COCO_val2014_000000131063   \n",
       "25991   person       other  COCO_val2014_000000131063   \n",
       "25992   marble       other  COCO_val2014_000000131063   \n",
       "25993    clean       other  COCO_val2014_000000131063   \n",
       "\n",
       "                                label  \\\n",
       "0                       black, blonde   \n",
       "1                                wine   \n",
       "2         fashion, style, they aren't   \n",
       "3         wedding, wine, wine tasting   \n",
       "4                       brick, bricks   \n",
       "...                               ...   \n",
       "25989      100, 20, 40, 50, lot, many   \n",
       "25990                             yes   \n",
       "25991    family, people, woman, women   \n",
       "25992  bathroom, don't know, not sure   \n",
       "25993                       cluttered   \n",
       "\n",
       "                                             question  question_id  \\\n",
       "0        What color is the woman's shirt on the left?    393267000   \n",
       "1           What type of beverage is being displayed?    393267001   \n",
       "2                   Why are some people wearing hats?    393267002   \n",
       "3      What kind of event are the people involved in?    393267003   \n",
       "4                         What is the ground made of?    262228000   \n",
       "...                                               ...          ...   \n",
       "25989                       How many tiles are there?    131063001   \n",
       "25990        Was this photo taken at someone's house?    131063002   \n",
       "25991                         Who uses this bathroom?    131063003   \n",
       "25992  What is the name of this his and her bathroom?    131063004   \n",
       "25993              Is this bathroom clean or clutter?    131063005   \n",
       "\n",
       "           question_type  score  \\\n",
       "0      what color is the    0.0   \n",
       "1           what type of    1.0   \n",
       "2                    why    0.0   \n",
       "3           what kind of    0.0   \n",
       "4            what is the    1.0   \n",
       "...                  ...    ...   \n",
       "25989           how many    0.0   \n",
       "25990                was    0.0   \n",
       "25991  none of the above    0.0   \n",
       "25992   what is the name    0.0   \n",
       "25993            is this    0.0   \n",
       "\n",
       "                                                 img_url  \n",
       "0      http://images.cocodataset.org/val2014/COCO_val...  \n",
       "1      http://images.cocodataset.org/val2014/COCO_val...  \n",
       "2      http://images.cocodataset.org/val2014/COCO_val...  \n",
       "3      http://images.cocodataset.org/val2014/COCO_val...  \n",
       "4      http://images.cocodataset.org/val2014/COCO_val...  \n",
       "...                                                  ...  \n",
       "25989  http://images.cocodataset.org/val2014/COCO_val...  \n",
       "25990  http://images.cocodataset.org/val2014/COCO_val...  \n",
       "25991  http://images.cocodataset.org/val2014/COCO_val...  \n",
       "25992  http://images.cocodataset.org/val2014/COCO_val...  \n",
       "25993  http://images.cocodataset.org/val2014/COCO_val...  \n",
       "\n",
       "[25994 rows x 9 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  what color is the\n",
      "Score:  0.7312953995157384\n",
      "Question:  what type of\n",
      "Score:  0.5243353783231084\n",
      "Question:  why\n",
      "Score:  0.15159574468085107\n",
      "Question:  what kind of\n",
      "Score:  0.5130116959064327\n",
      "Question:  what is the\n",
      "Score:  0.42981684981684987\n",
      "Question:  are these\n",
      "Score:  0.7264864864864865\n",
      "Question:  none of the above\n",
      "Score:  0.5401886792452829\n",
      "Question:  what is on the\n",
      "Score:  0.40355731225296443\n",
      "Question:  is this\n",
      "Score:  0.7249492900608518\n",
      "Question:  how many\n",
      "Score:  0.4489361702127659\n",
      "Question:  does this\n",
      "Score:  0.7291338582677165\n",
      "Question:  does the\n",
      "Score:  0.7294594594594594\n",
      "Question:  is the person\n",
      "Score:  0.7413461538461538\n",
      "Question:  are\n",
      "Score:  0.6915492957746479\n",
      "Question:  how many people are\n",
      "Score:  0.5265560165975104\n",
      "Question:  is the man\n",
      "Score:  0.7443661971830986\n",
      "Question:  do\n",
      "Score:  0.7427710843373495\n",
      "Question:  is it\n",
      "Score:  0.8524137931034482\n",
      "Question:  are there\n",
      "Score:  0.762883435582822\n",
      "Question:  what\n",
      "Score:  0.4233468972533062\n",
      "Question:  is the\n",
      "Score:  0.7367525522605737\n",
      "Question:  is there\n",
      "Score:  0.731358024691358\n",
      "Question:  are the\n",
      "Score:  0.7111111111111111\n",
      "Question:  is that a\n",
      "Score:  0.6895833333333333\n",
      "Question:  who is\n",
      "Score:  0.3421875\n",
      "Question:  are there any\n",
      "Score:  0.715483870967742\n",
      "Question:  what is in the\n",
      "Score:  0.4436464088397789\n",
      "Question:  was\n",
      "Score:  0.8178217821782178\n",
      "Question:  what is\n",
      "Score:  0.3790155440414508\n",
      "Question:  is there a\n",
      "Score:  0.6885714285714286\n",
      "Question:  what is the person\n",
      "Score:  0.650574712643678\n",
      "Question:  which\n",
      "Score:  0.43838028169014087\n",
      "Question:  where is the\n",
      "Score:  0.32887931034482754\n",
      "Question:  what does the\n",
      "Score:  0.24210526315789477\n",
      "Question:  is this a\n",
      "Score:  0.7441441441441441\n",
      "Question:  is\n",
      "Score:  0.7221153846153846\n",
      "Question:  how\n",
      "Score:  0.24385382059800667\n",
      "Question:  what color are the\n",
      "Score:  0.7093198992443326\n",
      "Question:  what is the man\n",
      "Score:  0.5947194719471947\n",
      "Question:  what room is\n",
      "Score:  0.9106796116504853\n",
      "Question:  is he\n",
      "Score:  0.7852941176470588\n",
      "Question:  what time\n",
      "Score:  0.26045454545454544\n",
      "Question:  can you\n",
      "Score:  0.6185185185185186\n",
      "Question:  what are the\n",
      "Score:  0.4648241206030151\n",
      "Question:  has\n",
      "Score:  0.6775510204081632\n",
      "Question:  what is the name\n",
      "Score:  0.09195402298850573\n",
      "Question:  what is this\n",
      "Score:  0.552582159624413\n",
      "Question:  what number is\n",
      "Score:  0.055696202531645575\n",
      "Question:  what are\n",
      "Score:  0.5265624999999999\n",
      "Question:  are they\n",
      "Score:  0.7248520710059172\n",
      "Question:  could\n",
      "Score:  0.7342465753424656\n",
      "Question:  is this person\n",
      "Score:  0.7448979591836735\n",
      "Question:  what color\n",
      "Score:  0.664039408866995\n",
      "Question:  what animal is\n",
      "Score:  0.5967391304347827\n",
      "Question:  what brand\n",
      "Score:  0.4186991869918699\n",
      "Question:  what sport is\n",
      "Score:  0.9230769230769231\n",
      "Question:  what color is\n",
      "Score:  0.8072847682119205\n",
      "Question:  is this an\n",
      "Score:  0.6125\n",
      "Question:  is the woman\n",
      "Score:  0.7444444444444445\n",
      "Question:  what is the woman\n",
      "Score:  0.6438095238095237\n",
      "Question:  what is the color of the\n",
      "Score:  0.7174757281553399\n",
      "Question:  how many people are in\n",
      "Score:  0.49687499999999996\n",
      "Question:  why is the\n",
      "Score:  0.154\n",
      "Question:  do you\n",
      "Score:  0.7373626373626373\n",
      "Question:  where are the\n",
      "Score:  0.29520547945205483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'other': 0.5070316186880603,\n",
       " 'yes/no': 0.7418102130261952,\n",
       " 'number': 0.3946382242721245}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_per_question(df)\n",
    "validation_per_answer(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lxmert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
