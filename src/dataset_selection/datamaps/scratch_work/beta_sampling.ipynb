{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pickle files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('variability_vqa_multilabel.pkl', 'rb') as f:\n",
    "    variability_scores = pickle.load(f)\n",
    "\n",
    "with open('confidence_vqa_multilabel.pkl', 'rb') as f:\n",
    "    confidence_scores = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(variability_scores) == len(confidence_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multithreaded function for score_samples since it takes a lot of time to run on its own \n",
    "\n",
    "def parallel_score_samples(kde, samples, thread_count=int(0.875 * multiprocessing.cpu_count())):\n",
    "    with multiprocessing.Pool(thread_count) as p:\n",
    "        return np.concatenate(p.map(kde.score_samples, np.array_split(samples, thread_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "beta = 1\n",
    "norm = 'gaussian'\n",
    "training_budget = 30\n",
    "bandwidth = 0.01\n",
    "\n",
    "num_total_samples = round(len(variability_scores) * (training_budget * 0.01)) # final number of samples training_budget * num_total samples\n",
    "beta_distribution = scipy.stats.beta(alpha, beta)\n",
    "p_vals = beta_distribution.pdf(variability_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if norm == 'pvals':\n",
    "    p_vals /= p_vals.sum()\n",
    "    plt.plot(variability_scores, p_vals, label='pdf')\n",
    "elif norm in ['gaussian', 'tophat', 'epanechnikov', 'exponential', 'linear', 'cosine']:\n",
    "    vars_kde =np.array(variability_scores).reshape(-1, 1)\n",
    "    kde = KernelDensity(bandwidth=bandwidth, kernel=norm, atol=0.0005, rtol=0.01)\n",
    "    kde.fit(vars_kde)\n",
    "    #kde = KernelDensity(bandwidth=2.0,atol=0.0005,rtol=0.01).fit(sample) \n",
    "    logprob = parallel_score_samples(kde, vars_kde)\n",
    "    # score_samples returns the log of the probability density\n",
    "    #logprob = kde.score_samples(vars_kde)\n",
    "    p_vals /= np.exp(logprob)\n",
    "    p_vals /= p_vals.sum()\n",
    "else:\n",
    "    print('Norm not implemented')\n",
    "\n",
    "\n",
    "selected_samples = np.random.choice(np.arange(len(variability_scores)), num_total_samples, replace=False, p=p_vals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lxmert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "408f321b22a65d7d3f121506280c03d9bcd580a47471795e8b6f8d70bb6ba487"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
